{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "color = sns.color_palette()\n",
    "\n",
    "import datetime\n",
    "import math\n",
    "import gc\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./data/\"\n",
    "train_data = pd.read_table(path + 'train.txt',sep=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_table(path + 'test.txt',sep=\" \")\n",
    "test_data['is_trade'] = 0\n",
    "train_data = pd.concat([train_data,test_data],ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "去掉重复样本，与test数据集保持一致"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"datetime\"] = train_data[\"context_timestamp\"].apply(lambda x: datetime.datetime.fromtimestamp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"day\"] = train_data[\"datetime\"].apply(lambda x: x.day)\n",
    "train_data[\"hour\"] = train_data[\"datetime\"].apply(lambda x: x.hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "按时间排序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.sort_values('context_timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"item_category_list\"] = train_data[\"item_category_list\"].apply(lambda x: x.split(\";\"))\n",
    "train_data[\"item_property_list\"] = train_data[\"item_property_list\"].apply(lambda x: x.split(\";\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = train_data[\"predict_category_property\"].apply(lambda x: x.split(\";\"))\n",
    "train_data[\"num_query_cat\"] = categories.apply(lambda x: len(x))\n",
    "for i in range(categories.apply(lambda x: len(x)).max()):\n",
    "    train_data[\"category_\"+str(i)] = categories.apply(lambda x: x[i].split(\":\")[0] if len(x)>i else \"-1\")\n",
    "    train_data[\"category_\"+str(i)+\"_props\"] = categories.apply(lambda x: x[i].split(\":\")[1].split(\",\") if len(x)>i and x[i].split(\":\")[0] != \"-1\" else [\"-1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query_corr(df):\n",
    "    data = df[[ 'category_0',\n",
    "       'category_0_props', 'category_1', 'category_1_props', 'category_2',\n",
    "       'category_2_props', 'category_3', 'category_3_props', 'category_4',\n",
    "       'category_4_props', 'category_5', 'category_5_props', 'category_6',\n",
    "       'category_6_props', 'category_7', 'category_7_props', 'category_8',\n",
    "       'category_8_props', 'category_9', 'category_9_props', 'category_10',\n",
    "       'category_10_props', 'category_11', 'category_11_props', 'category_12',\n",
    "       'category_12_props', 'category_13', 'category_13_props','item_property_list','item_category_list',\n",
    "        'num_query_cat','cat_prop_corr','cat_corr']].values\n",
    "    \n",
    "    for list in data:\n",
    "        count1 = 0\n",
    "        count2 = 0\n",
    "        for num in range(list[-3]):\n",
    "            if list[num*2] != \"-1\" and list[num*2] in list[-4]:\n",
    "                count1 = count1 + 1 + list[-4].index(list[num*2])\n",
    "                for prop in list[num*2+1]:\n",
    "                    if prop != \"-1\" and prop in list[-5]:\n",
    "                        count2 = count2 + 1\n",
    "        list[-1] = count1\n",
    "        list[-2] = count2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"cat_corr\"] = 0\n",
    "train_data[\"cat_prop_corr\"] = 0\n",
    "get_query_corr(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"num_item_category\"] = train_data[\"item_category_list\"].apply(lambda x: len(x)-x.count(\"-1\"))\n",
    "train_data[\"num_item_property\"] = train_data[\"item_property_list\"].apply(lambda x: len(x)-x.count(\"-1\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "统计各类别在此次出现前的count数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_cat_prep(df,column,newcolumn):\n",
    "    count_dict = {}\n",
    "    df[newcolumn] = 0\n",
    "    data = df[[column,newcolumn]].values\n",
    "    for cat_list in data:\n",
    "        if cat_list[0] not in count_dict:\n",
    "            count_dict[cat_list[0]] = 0\n",
    "            cat_list[1] = 0\n",
    "        else:\n",
    "            count_dict[cat_list[0]] += 1\n",
    "            cat_list[1] = count_dict[cat_list[0]]\n",
    "    df[[column,newcolumn]] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['user_item_id'] = train_data['user_id'].astype(str)+\"_\"+train_data['item_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['user_shop_id'] = train_data['user_id'].astype(str)+\"_\"+train_data['shop_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['user_brand_id'] = train_data['user_id'].astype(str)+\"_\"+train_data['item_brand_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['item_category'] = train_data['item_category_list'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['user_category_id'] = train_data['user_id'].astype(str)+\"_\"+train_data['item_category'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "统计各类别在总样本中的count数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in ['user_id','item_id','item_brand_id','shop_id','user_item_id','user_shop_id','user_brand_id','user_category_id']:\n",
    "    count_cat_prep(train_data,column,column+'_click_count_prep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in ['user_id','item_id','item_brand_id','shop_id','user_item_id','user_shop_id','user_brand_id','user_category_id']:\n",
    "    train_data = train_data.join(train_data[column].value_counts(),on = column ,rsuffix = '_count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前一次或后一次点击与现在的时间差（trick）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasttime_delta(column):    \n",
    "    train_data[column+'_lasttime_delta'] = 0\n",
    "    data = train_data[['context_timestamp',column,column+'_lasttime_delta']].values\n",
    "    lasttime_dict = {}\n",
    "    for df_list in data:\n",
    "        if df_list[1] not in lasttime_dict:\n",
    "            df_list[2] = -1\n",
    "            lasttime_dict[df_list[1]] = df_list[0]\n",
    "        else:\n",
    "            df_list[2] = df_list[0] - lasttime_dict[df_list[1]]\n",
    "            lasttime_dict[df_list[1]] = df_list[0]\n",
    "    train_data[['context_timestamp',column,column+'_lasttime_delta']] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nexttime_delta(column):    \n",
    "    train_data[column+'_nexttime_delta'] = 0\n",
    "    data = train_data[['context_timestamp',column,column+'_nexttime_delta']].values\n",
    "    nexttime_dict = {}\n",
    "    for df_list in data:\n",
    "        if df_list[1] not in nexttime_dict:\n",
    "            df_list[2] = -1\n",
    "            nexttime_dict[df_list[1]] = df_list[0]\n",
    "        else:\n",
    "            df_list[2] = nexttime_dict[df_list[1]] - df_list[0]\n",
    "            nexttime_dict[df_list[1]] = df_list[0]\n",
    "    train_data[['context_timestamp',column,column+'_nexttime_delta']]= data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in ['user_id','item_id','item_brand_id','shop_id','user_item_id','user_shop_id','user_brand_id','user_category_id']:\n",
    "    lasttime_delta(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.sort_values('context_timestamp',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in ['user_id','item_id','item_brand_id','shop_id','user_item_id','user_shop_id','user_brand_id','user_category_id']:\n",
    "    nexttime_delta(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.sort_values('context_timestamp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对各类别ctr转化率做贝叶斯平滑\n",
    "18用19,20号数据进行预估\n",
    "19用18号数据预估\n",
    "20号用18,19号数据预估\n",
    "21号用18,19,20号数据预估\n",
    "以此类推"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ctr_PH import ctr_PH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in ['item_city_id','item_id','item_brand_id','user_id','shop_id']:\n",
    "    train_data[column+'_PH_ctr'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = train_data[np.logical_and(train_data.day>18,train_data.day<=20)]\n",
    "dic_PH = ctr_PH(df_train,train_data[train_data.day==18],'item_city_id',50000,0.0000001)\n",
    "train_data.loc[train_data.day==18,'item_city_id'+'_PH_ctr'] = train_data.loc[train_data.day==18,'item_city_id'].apply(lambda x: dic_PH[x])\n",
    "        \n",
    "dic_PH = ctr_PH(df_train,train_data[train_data.day==18],'item_id',1000,0.002)\n",
    "train_data.loc[train_data.day==18,'item_id'+'_PH_ctr'] = train_data.loc[train_data.day==18,'item_id'].apply(lambda x: dic_PH[x])\n",
    "        \n",
    "dic_PH = ctr_PH(df_train,train_data[train_data.day==18],'item_brand_id',1000,0.002)\n",
    "train_data.loc[train_data.day==18,'item_brand_id'+'_PH_ctr'] = train_data.loc[train_data.day==18,'item_brand_id'].apply(lambda x: dic_PH[x])\n",
    "        \n",
    "dic_PH = ctr_PH(df_train,train_data[train_data.day==18],'user_id',50,0.002)\n",
    "train_data.loc[train_data.day==18,'user_id'+'_PH_ctr'] = train_data.loc[train_data.day==18,'user_id'].apply(lambda x: dic_PH[x])\n",
    "        \n",
    "dic_PH = ctr_PH(df_train,train_data[train_data.day==18],'shop_id',1000,0.002)\n",
    "train_data.loc[train_data.day==18,'shop_id'+'_PH_ctr'] = train_data.loc[train_data.day==18,'shop_id'].apply(lambda x: dic_PH[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for day in train_data.day.unique():\n",
    "    if day != 18:\n",
    "        df_train = train_data[train_data.day<day]\n",
    "        dic_PH = ctr_PH(df_train,train_data[train_data.day==day],'item_city_id',50000,0.0000001)\n",
    "        train_data.loc[train_data.day==day,'item_city_id'+'_PH_ctr'] = train_data.loc[train_data.day==day,'item_city_id'].apply(lambda x: dic_PH[x])\n",
    "        \n",
    "        dic_PH = ctr_PH(df_train,train_data[train_data.day==day],'item_id',1000,0.002)\n",
    "        train_data.loc[train_data.day==day,'item_id'+'_PH_ctr'] = train_data.loc[train_data.day==day,'item_id'].apply(lambda x: dic_PH[x])\n",
    "        \n",
    "        dic_PH = ctr_PH(df_train,train_data[train_data.day==day],'item_brand_id',1000,0.002)\n",
    "        train_data.loc[train_data.day==day,'item_brand_id'+'_PH_ctr'] = train_data.loc[train_data.day==day,'item_brand_id'].apply(lambda x: dic_PH[x])\n",
    "        \n",
    "        #dic_PH = ctr_PH(df_train,train_data[train_data.day==day],'user_id',50,0.002)\n",
    "        #train_data.loc[train_data.day==day,'user_id'+'_PH_ctr'] = train_data.loc[train_data.day==day,'user_id'].apply(lambda x: dic_PH[x])\n",
    "        \n",
    "        dic_PH = ctr_PH(df_train,train_data[train_data.day==day],'shop_id',1000,0.002)\n",
    "        train_data.loc[train_data.day==day,'shop_id'+'_PH_ctr'] = train_data.loc[train_data.day==day,'shop_id'].apply(lambda x: dic_PH[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = train_data[train_data.day<25]\n",
    "dic_PH = ctr_PH(df_train,train_data[train_data.day==25],'item_city_id',50000,0.0000001)\n",
    "train_data.loc[train_data.day==25,'item_city_id'+'_PH_ctr'] = train_data.loc[train_data.day==25,'item_city_id'].apply(lambda x: dic_PH[x])\n",
    "        \n",
    "dic_PH = ctr_PH(df_train,train_data[train_data.day==25],'item_id',1000,0.002)\n",
    "train_data.loc[train_data.day==25,'item_id'+'_PH_ctr'] = train_data.loc[train_data.day==25,'item_id'].apply(lambda x: dic_PH[x])\n",
    "        \n",
    "dic_PH = ctr_PH(df_train,train_data[train_data.day==25],'item_brand_id',1000,0.002)\n",
    "train_data.loc[train_data.day==25,'item_brand_id'+'_PH_ctr'] = train_data.loc[train_data.day==25,'item_brand_id'].apply(lambda x: dic_PH[x])\n",
    "        \n",
    "dic_PH = ctr_PH(df_train,train_data[train_data.day==25],'user_id',50,0.002)\n",
    "train_data.loc[train_data.day==25,'user_id'+'_PH_ctr'] = train_data.loc[train_data.day==25,'user_id'].apply(lambda x: dic_PH[x])\n",
    "        \n",
    "dic_PH = ctr_PH(df_train,train_data[train_data.day==25],'shop_id',1000,0.002)\n",
    "train_data.loc[train_data.day==25,'shop_id'+'_PH_ctr'] = train_data.loc[train_data.day==25,'shop_id'].apply(lambda x: dic_PH[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "统计各类别在此次出现前的trade转化数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trade_prep_count(column):\n",
    "    train_data[column+'_trade_prep_count'] = 0\n",
    "    for day in train_data.day.unique():\n",
    "        if day == 18:\n",
    "            train_data.loc[train_data.day==day,column+'_trade_prep_count'] = -1\n",
    "        else:\n",
    "            trade_dict = train_data[train_data.day<day].groupby(column)['is_trade'].sum().to_dict()\n",
    "            train_data.loc[train_data.day==day,column+'_trade_prep_count'] = train_data.loc[train_data.day==day,column].apply(lambda x: trade_dict[x] if x in trade_dict else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in ['user_id','item_id','item_brand_id','shop_id','user_item_id','user_shop_id','user_brand_id','user_category_id']:\n",
    "    trade_prep_count(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['item_price_level', 'item_sales_level',\n",
    "                 'item_pv_level', 'user_gender_id', 'user_occupation_id',\n",
    "                'user_age_level', \n",
    "                'context_page_id', 'hour', 'shop_review_num_level',\n",
    "            \"shop_star_level\",  \"user_star_level\" , \"item_collected_level\",\n",
    "        'item_category']:\n",
    "    df_train = train_data[train_data.day<25]\n",
    "    train_data[i+'_PH_ctr'] = 0\n",
    "    dic_PH = ctr_PH(df_train,train_data,i,10000,0.00001)\n",
    "    train_data[i+'_PH_ctr'] = train_data[i].apply(lambda x: dic_PH[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对特征进行强行交叉后，利用xgboost进行特征选择"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_prop_list = [\n",
    " 'item_price_level',\n",
    " 'item_sales_level',\n",
    " 'item_pv_level', 'item_collected_level','item_category']\n",
    "\n",
    "user_prop_list = [ 'user_gender_id',\n",
    " 'user_occupation_id',\n",
    " 'user_age_level','user_star_level']\n",
    "\n",
    "\n",
    "shop_prop_list = ['shop_review_num_level',\n",
    " 'shop_star_level']\n",
    " \n",
    "other_prop_list = ['context_page_id',\n",
    " 'hour']\n",
    "id_prop_list = ['item_brand_id','item_city_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_list = []\n",
    "ctr_list = []\n",
    "for item_prop in item_prop_list:\n",
    "    for user_prop in user_prop_list:\n",
    "        train_data[item_prop+'_'+user_prop] = train_data[item_prop].astype(str)+train_data[user_prop].astype(str)\n",
    "        cross_list.append(item_prop+'_'+user_prop)\n",
    "        ctr_list.append(item_prop+'_'+user_prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for other_prop in other_prop_list:\n",
    "    for prop in user_prop_list:\n",
    "        train_data[prop+'_'+other_prop] = train_data[prop].astype(str)+train_data[other_prop].astype(str)\n",
    "        cross_list.append(prop+'_'+other_prop)\n",
    "        ctr_list.append(prop+'_'+other_prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user_prop in user_prop_list:\n",
    "    for shop_prop in shop_prop_list:\n",
    "        train_data[user_prop+'_'+shop_prop] = train_data[user_prop].astype(str)+train_data[shop_prop].astype(str)\n",
    "        cross_list.append(user_prop+'_'+shop_prop)\n",
    "        ctr_list.append(user_prop+'_'+shop_prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user_prop in user_prop_list:\n",
    "    for id_prop in id_prop_list:\n",
    "        train_data[user_prop+'_'+id_prop] = train_data[user_prop].astype(str)+'_'+train_data[id_prop].astype(str)\n",
    "        cross_list.append(user_prop+'_'+id_prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in cross_list:\n",
    "    count_cat_prep(train_data,column,column+'_click_count_prep')\n",
    "    trade_prep_count(column)\n",
    "    train_data = train_data.join(train_data[column].value_counts(),on = column ,rsuffix = '_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in cross_list:\n",
    "    lasttime_delta(column)\n",
    "train_data = train_data.sort_values('context_timestamp',ascending=False)\n",
    "for column in cross_list:\n",
    "    nexttime_delta(column)\n",
    "train_data = train_data.sort_values('context_timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['context_page_id_PH_ctr', 'hour', 'hour_PH_ctr', 'item_brand_id',\n",
    "       'item_brand_id_PH_ctr', 'item_brand_id_click_count_prep',\n",
    "       'item_brand_id_nexttime_delta', 'item_brand_id_trade_prep_count',\n",
    "       'item_category_PH_ctr', 'item_category_user_age_level_nexttime_delta',\n",
    "       'item_city_id', 'item_city_id_PH_ctr', 'item_collected_level',\n",
    "       'item_id', 'item_id_PH_ctr', 'item_id_click_count_prep',\n",
    "       'item_id_count', 'item_id_lasttime_delta', 'item_id_nexttime_delta',\n",
    "       'item_id_trade_prep_count', 'item_price_level',\n",
    "       'item_price_level_PH_ctr',\n",
    "       'item_price_level_user_star_level_nexttime_delta',\n",
    "       'item_pv_level_user_age_level_lasttime_delta',\n",
    "       'item_pv_level_user_occupation_id_click_count_prep',\n",
    "       'item_pv_level_user_occupation_id_lasttime_delta', 'item_sales_level',\n",
    "       'item_sales_level_PH_ctr',\n",
    "       'item_sales_level_user_gender_id_lasttime_delta',\n",
    "       'item_sales_level_user_star_level_nexttime_delta', 'num_item_property',\n",
    "       'shop_id', 'shop_id_PH_ctr', 'shop_id_click_count_prep',\n",
    "       'shop_id_count', 'shop_id_lasttime_delta', 'shop_id_nexttime_delta',\n",
    "       'shop_review_num_level_PH_ctr', 'shop_review_positive_rate',\n",
    "       'shop_score_delivery', 'shop_score_description', 'shop_score_service',\n",
    "       'shop_star_level', 'shop_star_level_PH_ctr', 'user_age_level',\n",
    "       'user_age_level_PH_ctr',\n",
    "       'user_age_level_shop_review_num_level_nexttime_delta',\n",
    "       'user_brand_id_lasttime_delta', 'user_category_id_click_count_prep',\n",
    "       'user_category_id_lasttime_delta', 'user_category_id_nexttime_delta',\n",
    "       'user_gender_id_item_brand_id_nexttime_delta',\n",
    "       'user_gender_id_item_brand_id_trade_prep_count', 'user_id_count',\n",
    "       'user_id_lasttime_delta', 'user_id_nexttime_delta',\n",
    "       'user_item_id_click_count_prep', 'user_item_id_lasttime_delta',\n",
    "       'user_item_id_nexttime_delta',\n",
    "       'user_occupation_id_item_city_id_click_count_prep',\n",
    "       'user_occupation_id_item_city_id_lasttime_delta',\n",
    "       'user_shop_id_lasttime_delta', 'user_shop_id_nexttime_delta',\n",
    "       'user_star_level', 'user_star_level_PH_ctr',\n",
    "       'user_star_level_hour_count',\n",
    "       'user_star_level_item_brand_id_nexttime_delta',\n",
    "       'user_star_level_item_city_id_lasttime_delta',\n",
    "       'user_star_level_item_city_id_nexttime_delta',\n",
    "       'user_star_level_item_city_id_trade_prep_count',\n",
    "       'user_star_level_shop_star_level_click_count_prep',\n",
    "       'user_star_level_shop_star_level_nexttime_delta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[features+['day','is_trade','instance_id']].to_csv(path+'all_feat_0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './data/'\n",
    "train_data = pd.read_csv(path+'all_feat_0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.set_index('Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.loc[train_data.day <= 24,['is_trade']+features].to_csv(path+'baseline_5_train.txt',index=False)\n",
    "train_data.loc[train_data.day == 25,['is_trade']+features].to_csv(path+'baseline_5_test.txt',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
