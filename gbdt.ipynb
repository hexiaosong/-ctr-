{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "color = sns.color_palette()\n",
    "\n",
    "import datetime\n",
    "import math\n",
    "import gc\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_duplicate = True\n",
    "drop_sim_feat = False\n",
    "use_corr = True\n",
    "use_prep_day = True\n",
    "use_cross = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./data/\"\n",
    "train_data = pd.read_table(path + 'train.txt',sep=\" \")\n",
    "test_data = pd.read_table(path + 'test.txt',sep=\" \")\n",
    "test_data['is_trade'] = 0\n",
    "train_data = pd.concat([train_data,test_data],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if drop_duplicate:\n",
    "    train_data = train_data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"datetime\"] = train_data[\"context_timestamp\"].apply(lambda x: datetime.datetime.fromtimestamp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"day\"] = train_data[\"datetime\"].apply(lambda x: x.day)\n",
    "train_data[\"hour\"] = train_data[\"datetime\"].apply(lambda x: x.hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "缺失值填充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in ['shop_review_positive_rate','shop_score_service', 'shop_score_delivery','shop_score_description']:\n",
    "    train_data.loc[train_data[column] == -1,column] = train_data.loc[train_data[column] != -1,column].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.loc[train_data['user_gender_id'] == -1,'user_gender_id'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.loc[train_data['user_age_level'] == -1,'user_age_level'] = 1003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.loc[train_data['user_occupation_id'] == -1,'user_occupation_id'] = 2005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.loc[train_data['user_star_level'] == -1,'user_star_level'] = 3006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "按时间排序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.sort_values('context_timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"item_category_list\"] = train_data[\"item_category_list\"].apply(lambda x: x.split(\";\"))\n",
    "train_data[\"item_property_list\"] = train_data[\"item_property_list\"].apply(lambda x: x.split(\";\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = train_data[\"predict_category_property\"].apply(lambda x: x.split(\";\"))\n",
    "train_data[\"num_query_cat\"] = categories.apply(lambda x: len(x))\n",
    "for i in range(categories.apply(lambda x: len(x)).max()):\n",
    "    train_data[\"category_\"+str(i)] = categories.apply(lambda x: x[i].split(\":\")[0] if len(x)>i else \"-1\")\n",
    "    train_data[\"category_\"+str(i)+\"_props\"] = categories.apply(lambda x: x[i].split(\":\")[1].split(\",\") if len(x)>i and x[i].split(\":\")[0] != \"-1\" else [\"-1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query_day = train_data.groupby(['user_id', 'day']).size().reset_index().rename(columns={0: 'user_query_day'})\n",
    "train_data = pd.merge(train_data, user_query_day, 'left', on=['user_id', 'day'])\n",
    "user_query_day_hour = train_data.groupby(['user_id', 'day', 'hour']).size().reset_index(\n",
    "                      ).rename(columns={0: 'user_query_day_hour'})\n",
    "train_data = pd.merge(train_data, user_query_day_hour, 'left',on=['user_id', 'day', 'hour'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "修改后用cat_prop_corr cat_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query_corr(df):\n",
    "    data = df[[ 'category_0',\n",
    "       'category_0_props', 'category_1', 'category_1_props', 'category_2',\n",
    "       'category_2_props', 'category_3', 'category_3_props', 'category_4',\n",
    "       'category_4_props', 'category_5', 'category_5_props', 'category_6',\n",
    "       'category_6_props', 'category_7', 'category_7_props', 'category_8',\n",
    "       'category_8_props', 'category_9', 'category_9_props', 'category_10',\n",
    "       'category_10_props', 'category_11', 'category_11_props', 'category_12',\n",
    "       'category_12_props', 'category_13', 'category_13_props','item_property_list','item_category_list',\n",
    "        'num_query_cat','cat_prop_corr','cat_corr']].values\n",
    "    \n",
    "    for list in data:\n",
    "        count1 = 0\n",
    "        count2 = 0\n",
    "        for num in range(list[-3]):\n",
    "            if list[num*2] != \"-1\" and list[num*2] in list[-4]:\n",
    "                count1 = count1 + 1 + list[-4].index(list[num*2])\n",
    "                for prop in list[num*2+1]:\n",
    "                    if prop != \"-1\" and prop in list[-5]:\n",
    "                        count2 = count2 + 1\n",
    "        list[-1] = count1\n",
    "        list[-2] = count2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_corr:\n",
    "    train_data[\"cat_corr\"] = 0\n",
    "    train_data[\"cat_prop_corr\"] = 0\n",
    "    get_query_corr(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"num_item_category\"] = train_data[\"item_category_list\"].apply(lambda x: len(x)-x.count(\"-1\"))\n",
    "train_data[\"num_item_property\"] = train_data[\"item_property_list\"].apply(lambda x: len(x)-x.count(\"-1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if drop_sim_feat:\n",
    "    train_data = train_data.drop([\"shop_score_delivery\", \"shop_star_level\", \"shop_score_description\", \"user_star_level\" , \"item_collected_level\"], axis=1)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "生成id信息的历史日志"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_history(df,column):\n",
    "    df[column + '_click_history']=''\n",
    "\n",
    "    dict={}\n",
    "    data = df[['instance_id',column,'is_trade',column+'_click_history']].values\n",
    "\n",
    "    for list in data:\n",
    "        user = list[1]\n",
    "        if user in dict:\n",
    "            if dict[user][0] == list[0]:\n",
    "                list[3] = dict[user][3]\n",
    "            else:\n",
    "                list[3] =dict[user][3] + str(dict[user][2])\n",
    "                dict[user] = list\n",
    "        else:\n",
    "                dict[user] = list\n",
    "    dict.clear()\n",
    "    \n",
    "    df[['instance_id',column,'is_trade',column+'_click_history']] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in ['user_id','item_id','item_brand_id','shop_id']:\n",
    "    create_history(train_data,column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in ['user_id','item_id','item_brand_id','shop_id']:\n",
    "    train_data[column+'_click_count_prep'] = train_data[column+'_click_history'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "统计商品被点击的主要影响属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_data = train_data.loc[train_data['is_trade']==1,:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query_item_props_and_cats(data):\n",
    "    for i in range(data.shape[0]):\n",
    "        props = ''\n",
    "        cats =''\n",
    "        for num in range(data.loc[i,\"num_query_cat\"]):\n",
    "            if data.loc[i,\"category_\"+str(num)] != \"-1\" and data.loc[i,\"category_\"+str(num)] in data.loc[i,\"item_category_list\"]:\n",
    "                if cats == '':\n",
    "                    cats = data.loc[i,\"category_\"+str(num)]\n",
    "                else:\n",
    "                    cats = cats+'_'+data.loc[i,\"category_\"+str(num)]\n",
    "                for prop in data.loc[i,\"category_\"+str(num)+\"_props\"]:\n",
    "                    if prop != \"-1\" and prop in data.loc[i,\"item_property_list\"]:\n",
    "                        if props == '':\n",
    "                            props = prop\n",
    "                        else:\n",
    "                            props = props+'_'+prop\n",
    "        data.loc[i,\"item_props\"] = props\n",
    "        data.loc[i,\"item_cats\"] = cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_data['item_props'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_data = trade_data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_query_item_props_and_cats(trade_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_data[\"item_props\"] = trade_data[\"item_props\"].apply(lambda x: x.split('_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listToDict(x):\n",
    "    dict = {}\n",
    "    for i in range(len(x)):\n",
    "        if x[i] != '':\n",
    "            if x[i] in dict:\n",
    "                dict[x[i]] += 1\n",
    "            else:\n",
    "                dict[x[i]] = 1\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.join(trade_data.groupby('item_id')['item_props'].sum(),on = 'item_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['item_props'] = train_data['item_props'].apply(lambda x: listToDict(x) if x is not np.nan else {})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在此次样本出现前用户可曾看过此广告，可曾trade过"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['user_item_id'] = train_data['user_id'].astype(str)+\"_\"+train_data['item_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['has_seen'] = 0\n",
    "train_data['has_trade'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['has_trade'] = train_data['user_item_id']+':'+train_data['is_trade'].astype(str)\n",
    "train_data['has_trade'] = train_data['has_trade'].apply(lambda x: x.split(\":\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_has_seen = {}\n",
    "def has_seen(x,dict):\n",
    "    if x not in dict:\n",
    "        dict[x] = 0\n",
    "    else:\n",
    "        dict[x] += 1\n",
    "    return dict[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy = train_data['user_item_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for list in yy:\n",
    "    yy[i] = has_seen(list,dict_has_seen)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['has_seen'] = train_data['user_item_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['has_seen'] = train_data['has_seen'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict2 = {}\n",
    "def has_trade(x,dict):\n",
    "    if x[0] not in dict:\n",
    "        if x[1]=='1':\n",
    "            dict[x[0]] = 1\n",
    "        else:\n",
    "            dict[x[0]] = 0\n",
    "        return 0\n",
    "    else:\n",
    "        if x[1]=='1':\n",
    "            dict[x[0]] += 1\n",
    "            return dict[x[0]] - 1\n",
    "        else:\n",
    "            return dict[x[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy = train_data['has_trade'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for list in yy:\n",
    "    yy[i] = has_trade(list,dict2)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['item_category_0'] = train_data['item_category_list'].apply(lambda x: x[0])\n",
    "train_data['item_category_1'] = train_data['item_category_list'].apply(lambda x: x[1])\n",
    "train_data['item_category_2'] = train_data['item_category_list'].apply(lambda x: x[2] if len(x)>2 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "统计总count数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in ['user_id','item_id','item_brand_id','shop_id']:\n",
    "    train_data = train_data.join(train_data[column].value_counts(),on = column ,rsuffix = '_count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对id类进行划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_user(x):\n",
    "    if x>=5 and x<=7:\n",
    "        return '5-7'\n",
    "    if x>7:\n",
    "        return '>7'\n",
    "    else:\n",
    "        return str(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['user_id_click_count_prep_cat'] = train_data['user_id_click_count_prep'].apply(lambda x: cat_user(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut(x,list):\n",
    "    for i in range(len(list)):\n",
    "        if x<=list[i]:\n",
    "            return i\n",
    "    return len(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in ['item_id','item_brand_id','shop_id']:\n",
    "    list_quantile = []\n",
    "    for i in range(1,21,1):\n",
    "        list_quantile.append(train_data[column+'_click_count_prep'].quantile(0.05*i))\n",
    "    train_data[column+'_click_count_prep_cat'] = train_data[column+'_click_count_prep'].apply(lambda x: cut(x,list_quantile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_id(x,list,thresh):\n",
    "    if x<thresh:\n",
    "        for i in range(len(list)):\n",
    "            if x<=list[i]:\n",
    "                return i\n",
    "    else:\n",
    "        return 'self'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in ['item_id','item_brand_id','shop_id']:\n",
    "    list_quantile = []\n",
    "    for i in range(1,21,1):\n",
    "        list_quantile.append(train_data[column+'_count'].quantile(0.05*i))\n",
    "    train_data[column+'_count_cat'] = train_data[column+'_count'].apply(lambda x: cut_id(x,list_quantile,500))\n",
    "    data = train_data[[column,column+'_count_cat']].values\n",
    "    for list in data:\n",
    "        if list[1] == 'self':\n",
    "            list[1] = list[0]\n",
    "    train_data[[column,column+'_count_cat']] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_quantile = []\n",
    "for i in range(1,21,1):\n",
    "    list_quantile.append(train_data['user_id_count'].quantile(0.05*i))\n",
    "train_data['user_id_count_cat'] = train_data['user_id_count'].apply(lambda x: cut_id(x,list_quantile,10))\n",
    "data = train_data[['user_id','user_id_count_cat']].values\n",
    "for list in data:\n",
    "    if list[1] == 'self':\n",
    "        list[1] = list[0]\n",
    "train_data[['user_id','user_id_count_cat']] = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "统计样本之前的trade数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trade_count(x):\n",
    "    sum = ''\n",
    "    for i in range(len(x)):\n",
    "        if x[i] == '1':\n",
    "            sum += x[i]\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in ['user_id','item_id','item_brand_id','shop_id']:\n",
    "    train_data[column+'_trade_count'] = train_data[column+'_click_history'].apply(lambda x: len(trade_count(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "商品最关键属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['key_prop'] = 0\n",
    "data = train_data[['category_0','category_0_props', 'category_1', 'category_1_props', 'category_2',\n",
    "       'category_2_props', 'category_3', 'category_3_props', 'category_4',\n",
    "       'category_4_props', 'category_5', 'category_5_props', 'category_6',\n",
    "       'category_6_props', 'category_7', 'category_7_props', 'category_8',\n",
    "       'category_8_props', 'category_9', 'category_9_props', 'category_10',\n",
    "       'category_10_props', 'category_11', 'category_11_props', 'category_12',\n",
    "       'category_12_props', 'category_13', 'category_13_props', 'key_prop', 'item_props','item_category_list','num_query_cat']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for list in data:\n",
    "    for i in range(list[-1]):\n",
    "        if list[2*i] in list[-2]:\n",
    "            for prop in list[2*i+1]:\n",
    "                if prop in list[-3]:\n",
    "                    list[-4] = max(list[-3][prop],list[-4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可改进 此处可使用prop或比值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[['category_0','category_0_props', 'category_1', 'category_1_props', 'category_2',\n",
    "       'category_2_props', 'category_3', 'category_3_props', 'category_4',\n",
    "       'category_4_props', 'category_5', 'category_5_props', 'category_6',\n",
    "       'category_6_props', 'category_7', 'category_7_props', 'category_8',\n",
    "       'category_8_props', 'category_9', 'category_9_props', 'category_10',\n",
    "       'category_10_props', 'category_11', 'category_11_props', 'category_12',\n",
    "       'category_12_props', 'category_13', 'category_13_props', 'key_prop', 'item_props','item_category_list','num_query_cat']] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_count(df,group_column,column):\n",
    "    dict_group = {}\n",
    "    data = df[[group_column,column]].values\n",
    "    for list in data:\n",
    "        if list[0] not in dict_group:\n",
    "            dict_group[list[0]] = list[1]\n",
    "        else:\n",
    "            list[1] = dict_group[list[0]]\n",
    "    df[[group_column,column]] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_prep_day:\n",
    "    for i in range(18,26,1):\n",
    "        data = train_data.loc[train_data['day'] == i,:].copy()\n",
    "        prep_count(data,'user_item_id','has_trade')\n",
    "        train_data.loc[train_data['day'] == i,:] = data\n",
    "    \n",
    "    for i in range(18,26,1):\n",
    "        data = train_data.loc[train_data['day'] == i,:].copy()\n",
    "        prep_count(data,'user_id','user_id_trade_count')\n",
    "        train_data.loc[train_data['day'] == i,:] = data\n",
    "    \n",
    "    for i in range(18,26,1):\n",
    "        data = train_data.loc[train_data['day'] == i,:].copy()\n",
    "        prep_count(data,'item_id','item_id_trade_count')\n",
    "        train_data.loc[train_data['day'] == i,:] = data\n",
    "    \n",
    "    for i in range(18,26,1):\n",
    "        data = train_data.loc[train_data['day'] == i,:].copy()\n",
    "        prep_count(data,'item_brand_id','item_brand_id_trade_count')\n",
    "        train_data.loc[train_data['day'] == i,:] = data\n",
    "    \n",
    "    for i in range(18,26,1):\n",
    "        data = train_data.loc[train_data['day'] == i,:].copy()\n",
    "        prep_count(data,'shop_id','shop_id_trade_count')\n",
    "        train_data.loc[train_data['day'] == i,:] = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "利用query分析用户偏好，并与商品类别属性进行交叉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cats(x):\n",
    "    list = x.split(';')\n",
    "    catlist = []\n",
    "    for entry in list:\n",
    "        catlist.append(entry.split(':')[0])\n",
    "    return catlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cat_props(x):\n",
    "    list = x.split(';')\n",
    "    dict={}\n",
    "    if x == '-1':\n",
    "        return dict\n",
    "    for entry in list:\n",
    "        cat_props = entry.split(':')\n",
    "        dict[cat_props[0]] = cat_props[1].split(',')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weight(x):\n",
    "    sum = 0\n",
    "    for key in x:\n",
    "        sum = max(sum,x[key])\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_cross:\n",
    "    train_data['user_int_cats'] = train_data['predict_category_property'].apply(lambda x: get_cats(x))\n",
    "    \n",
    "    data = train_data[['user_id','user_int_cats']].values\n",
    "    dict_0 = {}\n",
    "    for list in data:\n",
    "        if list[0] not in dict_0:\n",
    "            to_dict = {}\n",
    "        else:\n",
    "            to_dict = dict_0[list[0]]\n",
    "        for cat in list[1]:\n",
    "            if cat not in to_dict:\n",
    "                to_dict[cat] = 1\n",
    "            else:\n",
    "                to_dict[cat] += 1\n",
    "        dict_0[list[0]] = to_dict\n",
    "        \n",
    "    train_data['user_int_cat'] = train_data['user_id'].apply(lambda x: dict_0[x])\n",
    "    \n",
    "    train_data['category_property'] = train_data['predict_category_property'].apply(lambda x: create_cat_props(x))\n",
    "\n",
    "    data = train_data[['user_id','category_property']].values\n",
    "    dict_0.clear()\n",
    "    for list in data:\n",
    "        if list[0] not in dict_0:\n",
    "            to_dict = {}\n",
    "        else:\n",
    "            to_dict = dict_0[list[0]]\n",
    "        for cat in list[1]:\n",
    "            if cat not in to_dict:\n",
    "                to_dict[cat] = {}\n",
    "                for prop in list[1][cat]:\n",
    "                    if prop != '-1':\n",
    "                        to_dict[cat][prop] = 1\n",
    "            else:\n",
    "                for prop in list[1][cat]:\n",
    "                    if prop != '-1':\n",
    "                        if prop in to_dict[cat]:\n",
    "                            to_dict[cat][prop] += 1\n",
    "                        else:\n",
    "                            to_dict[cat][prop] = 1\n",
    "        dict_0[list[0]] = to_dict\n",
    "    \n",
    "    train_data['user_int_props'] = train_data['user_id'].apply(lambda x: dict_0[x])\n",
    "    dict_0.clear()\n",
    "    train_data['user_item_cross_prop'] = ''\n",
    "    train_data['user_item_cross_cat'] = ''\n",
    "    \n",
    "    data = train_data[['item_category_list','user_int_cat','user_item_cross_cat',\n",
    "                   'item_property_list','user_int_props','user_item_cross_prop']].values\n",
    "    for list in data:\n",
    "        list[2] = {}\n",
    "        list[-1] = {}\n",
    "        for cat in list[0]:\n",
    "            if cat != '7908382889764677758':\n",
    "                if cat in list[1]:\n",
    "                    list[2][cat] = list[1][cat]\n",
    "            for prop in list[3]:\n",
    "                if cat in list[4] and prop in list[4][cat]:\n",
    "                    list[-1][prop] = list[4][cat][prop]\n",
    "                    \n",
    "    train_data[['item_category_list','user_int_cat','user_item_cross_cat',\n",
    "                   'item_property_list','user_int_props','user_item_cross_prop']] = data\n",
    "    \n",
    "    train_data['cross_prop_num'] = train_data.user_item_cross_prop.apply(lambda x: len(x))\n",
    "    train_data['cross_cat_num'] = train_data.user_item_cross_cat.apply(lambda x: len(x))\n",
    "    train_data['cross_prop_weight'] = train_data.user_item_cross_prop.apply(lambda x: get_weight(x))\n",
    "    train_data['cross_cat_weight'] = train_data.user_item_cross_cat.apply(lambda x: get_weight(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[['cross_prop_num','cross_cat_num','cross_prop_weight','cross_cat_weight','key_prop']].to_csv(path+'cross_query.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算类别ctr（非id类）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_ctr(df,day,column):\n",
    "    ctr_dict = {}\n",
    "    for i in df.loc[df.day<day,column].unique():\n",
    "        ctr_dict[i] = df.loc[np.logical_and(df[column] == i,df.day<day),'is_trade'].mean()\n",
    "    return ctr_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ctr(df,day,ctr_count_list):\n",
    "    for column in ctr_count_list:\n",
    "        ctr_dict = count_ctr(df,day,column)\n",
    "        df[column+'_ctr'] = df[column].apply(lambda x: ctr_dict[x] if x in ctr_dict else -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctr(train_data,25,['item_price_level', 'item_sales_level',\n",
    "                 'item_pv_level', 'user_gender_id', 'user_occupation_id',\n",
    "                'user_age_level', \n",
    "                'context_page_id', 'hour', 'shop_review_num_level',\n",
    "            \"shop_star_level\",  \"user_star_level\" , \"item_collected_level\",\n",
    "        'item_category_1', 'item_category_2','cross_prop_num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将数据转化成libsvm格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pd_to_libsvm(df):    \n",
    "    libsvm = pd.DataFrame()  \n",
    "    idx = 0  \n",
    "    t = df.dtypes.to_dict()    \n",
    "    for col in df.columns:  \n",
    "        col_type = t[col]  \n",
    "        if col_type ==  'object':\n",
    "            col_value = df[col].unique()  \n",
    "            feat_dict = dict(zip(col_value,range(idx,idx+len(col_value))))  \n",
    "            libsvm[col] = df[col].apply(lambda x: str(feat_dict[x]) + ':' + '1')  \n",
    "            idx += len(col_value) \n",
    "        else:\n",
    "            libsvm[col] = df[col].apply(lambda x: str(idx) + ':' + str(x))\n",
    "            idx += 1\n",
    "    return libsvm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_libsvm_file(data,path,test_day,valid_day = -1):    \n",
    "    y = data['is_trade']\n",
    "    day_split = data['day']\n",
    "    x = data.drop(['is_trade','day'],axis=1)\n",
    "    ffm_x = pd_to_libsvm(x)\n",
    "    ffm = pd.DataFrame()\n",
    "    ffm['is_trade'] = y\n",
    "    ffm = ffm.merge(ffm_x,left_index=True,right_index=True)\n",
    "    if valid_day != -1:    \n",
    "        train = ffm.loc[np.logical_and(day_split != valid_day,day_split != test_day),:]\n",
    "        valid = ffm.loc[day_split == valid_day,:]\n",
    "        valid.to_csv(path+'_valid.txt', sep = ' ', header = False, index=False)\n",
    "    else:\n",
    "        train = ffm.loc[day_split != test_day,:]\n",
    "    test = ffm.loc[day_split == test_day,:]\n",
    "    test.to_csv(path+'_test.txt', sep = ' ', header = False, index=False)\n",
    "    train.to_csv(path+'_train.txt', sep = ' ', header = False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "选择训练新user的特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['item_id','item_brand_id','item_city_id','shop_id','item_price_level', 'item_sales_level',\n",
    "                 'item_pv_level', 'user_gender_id', 'user_occupation_id',\n",
    "                'user_age_level', \n",
    "                'context_page_id', 'hour',  'shop_review_num_level',\n",
    "                'shop_review_positive_rate', 'shop_score_service',\"shop_score_delivery\",\n",
    "            \"shop_star_level\", \"shop_score_description\", \"user_star_level\" , \"item_collected_level\",\n",
    "           'num_query_cat', 'cat_prop_corr',\n",
    "        'num_item_property','user_id_click_count_prep',\n",
    "       'item_id_click_count_prep', 'item_brand_id_click_count_prep',\n",
    "       'shop_id_click_count_prep', 'has_seen',\n",
    "       'has_trade','item_category_1', 'item_category_2', 'item_id_count', 'item_brand_id_count',\n",
    "       'shop_id_count','user_id_trade_count', 'item_id_trade_count',\n",
    "       'item_brand_id_trade_count', 'shop_id_trade_count','cross_prop_num', 'cross_prop_weight','user_id_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "选择训练老用户user的特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['item_id','item_brand_id','item_city_id','shop_id','item_price_level', 'item_sales_level',\n",
    "                 'item_pv_level', 'user_gender_id', 'user_occupation_id',\n",
    "                'user_age_level', 'user_query_day', 'user_query_day_hour',\n",
    "                'context_page_id', 'hour',  'shop_review_num_level',\n",
    "                'shop_review_positive_rate', 'shop_score_service',\"shop_score_delivery\",\n",
    "            \"shop_star_level\", \"shop_score_description\", \"user_star_level\" , \"item_collected_level\",\n",
    "           'num_query_cat', 'cat_prop_corr',\n",
    "        'num_item_property',\n",
    "       'item_id_click_count_prep', 'item_brand_id_click_count_prep',\n",
    "       'shop_id_click_count_prep','item_category_1', 'item_id_count', 'item_brand_id_count',\n",
    "       'shop_id_count', 'item_id_trade_count',\n",
    "       'item_brand_id_trade_count', 'shop_id_trade_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctr_column = [i+'_ctr' for i in ['item_price_level', 'item_sales_level',\n",
    "                 'item_pv_level', 'user_gender_id', 'user_occupation_id',\n",
    "                'user_age_level', \n",
    "                'context_page_id', 'hour', 'shop_review_num_level',\n",
    "            \"shop_star_level\",  \"user_star_level\" , \"item_collected_level\",\n",
    "        'item_category_1','cross_prop_num']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[(features+['is_trade','day']+ctr_column)].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_libsvm_file(train_data[features+['is_trade','day']+ctr_column],path+'baseline_0',25,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_libsvm_file(train_data.loc[train_data.user_id_click_count_prep!=0,features+['is_trade','day']+ctr_column],path+'baseline_1_old',25,-1)\n",
    "to_libsvm_file(train_data.loc[train_data.user_id_click_count_prep==0,features+['is_trade','day']+ctr_column],path+'baseline_1_new',25,-1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
